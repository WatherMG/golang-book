# UTF-8

`UTF-8` представляет собой кодировку переменной длины символов `Unicode` в виде байтов.
Кодировка `UFT-8` была изобретена двумя из создателей Go, Кеном Томпсоном и Робом Пайком, и в настоящее время является
стандартом `Unicode`.

Она использует от 1 до 4 байтов для представления каждой руны, но при этом только 1 байт для символов `ASCII` и только
2 или 3 байта для большинства распространенных рун. Старшие биты первого байта кодировки руны указывают, сколько байтов
следуют за первым. Нулевой старший бит указывает, что это 7-битовый символ ASCII, в котором каждая руна занимает только
1 байт (а потому он идентичен обычному ASCII).
Старшие биты `110` указывают, что руна занимает 2 байта. Второй байт при этом начинается с битов `10`.
Б***о***льшие руны имеют аналогичные кодировки.

| Старшие биты                        |      Руны      | Описание                        |
|:------------------------------------|:--------------:|:--------------------------------|
| 0xxxxxxx                            |     0-127      | ASCII                           |
| 110xxxxx 10xxxxxx                   |    128-2047    | Значения < 128 не используются  |
| 1110xxxx 10xxxxxx 10xxxxxx          |   2048-65535   | Значения < 2048 не используются |
| 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx | 65536-0x10ffff | Прочие значения не используются |

Переменная длина кодировки исключает возможность прямой индексации для доступа к n-му символу строки, но `UTF-8` имеет
множество полезных свойств, компенсирующих этот недостаток.
Кодировка **компактна**, **совместима с `ASCII`** и обладает свойством **_самосинхронизации_**: всегда можно найти
начало символа, просмотрев не более, чем три байта. Этот код является **префиксным**, так что его можно декодировать
слева направо без каких-либо неоднозначностей или предпросмотра.
Никакой код руны не является подстрокой другого кода или даже последовательности других кодов, так что можно искать руны
с помощью простого поиска составляющие ее байтов, не беспокоясь о контексте.
Лексикографический порядок байтов соответствует порядку кода Unicode, так что сортировка `UTF-8` работает естественным
образом.
Не существует встроенных нулевых байтов, что удобно для языков программирования, в которых используются нулевые символы
для завершения строк.

Исходные файлы Go всегда закодированы с использованием кодировки `UTF-8`, и эта кодировка является предпочтительной для
текстовых строк в Go.

Пакет `unicode` предоставляет функции для работы с отдельными рунами (например, чтобы отличать буквы от цифр или
преобразовывать прописные буквы в строчные), а пакет `unicode/utf8` предоставляет функции для кодирования и
декодирования рун в виде байтов с использованием `UTF-8`.

Многие символы Unicode Трудно набирать на клавиатуре или визуально отличить от других, визуально схожих (некоторые из
них просто невидимы).

Управляющие последовательности Unicode в строковых литералах Go позволяют указывать символы Unicode с помощью их
числового кода.
Существуют две разновидности управляющих последовательностей - `'\uhhhh'` для 16-разрядных значений и `'\uhhhhhhhh'` для
32-разрядных, где каждое h является шестнадцатеричной цифрой.
Каждая из управляющих последовательностей представляет собой кодировку `UTF-8` указанного символа Unicode.
Таким образом, все приведенные ниже строковые литералы представляют одну и ту же шестибайтовую строку:

``` go 
"世界"
"\xe4\xb8\x96\xe7\x95\x8c"
"\u4e16\u754c"
"\U00004e16\U0000754c"
```

Три приведенных выше строки с управляющими последовательностями представляют собой альтернативную запись первой строки,
но значения, которые они описывают одинаковы.

Управляющие последовательности Unicode могут использоваться и для литералов рун. Приведенные далее три литерала
эквивалентны:

``` go
'世' '\u4e16' '\U00004e16'
```

Руна, значение которой меньше 256, может быть записана с помощью одной шестнадцатеричной управляющей последовательности,
такой как `'\x41'` для `'A'`, но для более высоких значений следует использовать управляющие последовательности `'\u'`
или `'\U'`. Следовательно, `'\xe4\xb8\x96'` не является корректным литералом руны, несмотря на то, что эти три байта
являются корректной кодировкой `UTF-8` одного символа Unicode.

Благодаря указанны выше свойствам `UTF-8 ` многие строковые операции не требуют декодирования. Можно проверить, не
содержит ли одна строка другую в качестве префикса:

``` go
func HasPrefix(s, prefix string) bool {
    return len(s) >= len(prefix) && s[:len(prefix)] == prefix
}
```

Или в качестве суффикса:

``` go
func HasSuffix(s, suffix string) bool {
    return len(s) >= len(suffix) && s[len(s)-len(suffix):] == suffix
}
```

Или в качестве подстроки Используя для закодированного с помощью кодировки UTF-8 текста ту же логику, что и для обычной
последовательности байтов:

``` go
func Contains(s, substr string) bool {
    for i := 0; i < len(s); i++ {
        if HasPrefix(s[i:], substr) {
            return true
        }
    }
    return false
}
```

Для других кодировок это было бы неверным решением. (Приведенные выше функции взяты из пакета `strings`, хотя
реализация функции `Contains` в этом пакете для более эффективного поиска использует хеширование (В Go использует
алгоритм
поиска Рабина-Карпа)).

С другой стороны, если нас действительно интересуют отдельные символы Unicode, то нужно использовать другие механизмы.
Рассмотрим строку, которая включает в себя два иероглифа. На рисунке показано ее представление в памяти.
Строка содержит 13 байт, но если интерпретировать ее как UTF-8, то в ней закодировано только девять кодов Unicode, или
рун:

``` go
s := "Hello, 世界"
fmt.Println(len(s)) // "13"
fmt.Println(utf8.RuneCountInString(s)) // "9"
```

![img.png](img.png)

Для работы с этими символами необходимо декодирование UTF-8. Пакет `unicode/utf8` предоставляет декодер, который мы
можем использовать следующим образом:

``` go
for i := 0; i < len(s); {
	r, size := utf8.DecodeRuneInString(s[i:])
	fmt.Printf("%d\t%c\n", i, r)
	i += size
}
```

Каждый вызов `DecodeRuneInString()` возвращает `r` (саму руну) и size (количество байтов, занятых `UTF-8` кодом `r`).
Размер используется для обновления индекса байтов `i` для следующей руны в строке (это неуклюжее решение).

Цикл по диапазону Go, будучи примененным к строке, выполняет декодирование `UTF-8` **_неявно_**. Вывод приведенного ниже
цикла показан на рисунке. Внимание на то, как индекс перемещается более чем на один байт для каждой руны, не являющейся
ASCII символом.

``` go
for i, r := range "Hello, 世界" {
	fmt.Printf("%d\t%q\t%d\n", i, r, r)
}
```

Для подсчета количества рун в строке можно использовать простой цикл `range`:

``` go
n := 0
for _, _ := range s {
    n++
}
```

Как и в прочих разновидностях цикла `range`, можно опустить ненужные нам переменные:

``` go
n := 0
for range s {
 n++
}
```

Для решения этой задачи можно также просто вызвать `utf8.RuneCountInString(s)`.

**_Тексты строк в Go интерпретируются как последовательности символов Unicode в кодировке UTF-8_**, в основном по
соглашению, но для правильного использования циклов по диапазону - это _**необходимость_**.

Если мы применим такой цикл к строке, содержащей произвольные бинарные данные или данные UTF-8 содержащие ошибки,
декодер UFT-8, получая при явном вызове `utf8.DecodeRuneInString()` или неявно в цикле по диапазону некорректный входной
байт, генерирует специальный **_замещающий символ Unicode_**, `'\uFFFD'`, который обычно выглядит как белый
вопросительный знак в черном ромбе.
Когда программа встречает руну с этим значением, это, как правило, означает, что некая часть системы, генерирующей
строковые данные, была некорректна в трактовке закодированного текста.

Кодировка UTF-8 оказывается исключительно удобной в качестве формата обмена данными, но в пределах программы руны могут
оказаться более удобными, поскольку имеют одинаковый размер и, таким образом, легко индексируются в массивах и срезах.

Преобразование `[]rune`, примененное к строке в кодировке UTF-8, возвращает последовательность символов `Unicode`,
закодированную в этой строке:

``` go
// Слово "программа", записанное по-японски на катакане
s := "プログラム"
fmt.Printf("% x\n", s) // e3 83 97 e3 83 ad e3 82 b0 e3 83 a9 e3 83 a0
r := []rune(s)
fmt.Printf("%x\n", r) // [30d7 30ed 30b0 30e9 30e0]
```

Символы преобразования `% x` в первом вызове `Printf` вставляют пробелы между каждой парой шестнадцатеричных цифр.

Если срез рун преобразуется в строку, генерируется конкатенация UTF-8 кодов для каждой руны:

``` go
fmt.Println(string(r)) // プログラム
```

Преобразование целочисленного значения в строку рассматривает это целочисленное значение как значение руны и дает
представление этой руны в кодировке UTF-8:

``` go
fmt.Println(string(65)) // "A", но не "65"
fmt.Println(string(0x4eac)) // "C"
```

Если руна некорректна, вместо нее подставляется замещающий символ `�`:

``` go
fmt.Println(string(1234567)) // "�"
```

## Выводы:

* `UTF-8` - это кодировка переменной длины символов `Unicode` в виде байтов, изобретенная Кеном Томпсоном и Робом
  Пайком, является стандартом `Unicode`;
* Руны в `UTF-8` могут использовать `от 1 до 4 байтов`, но символы `ASCII` занимают только `1 байт`, большинство
  распространенных рун используют `2` или `3 байта`;
* `UTF-8` обладает свойством самосинхронизации (можно найти начало символа, просмотрев не более 3 байт) и совместимости
  с `ASCII`, что упрощает работу с текстом;
* Для работы с отдельными рунами в Go можно использовать пакеты `unicode` и `unicode/utf8`, которые предоставляют
  функции для кодирования, декодирования и обработки рун;
* Управляющие последовательности `Unicode` в строковых литералах Go позволяют указывать символы с помощью их числового
  кода: `'\uhhhh'` для 16-разрядных значений и `'\uhhhhhhhh'` для 32-разрядных;
* `UTF-8` позволяет проводить некоторые строковые операции без декодирования, например, проверить является ли одна
  строка префиксом, суффиксом или содержит ли подстроку другой строки;
* Если необходимо работать с отдельными символами `Unicode`, нужно использовать другие механизмы, такие как функция
  `utf8.RuneCountInString()` для определения количества рун в строке;
* Для работы с символами `Unicode` в Go необходимо декодирование `UTF-8`, для этого можно использовать
  пакет `unicode/utf8`;
* При декодировании с помощью функции `utf8.DecodeRuneInString()` возвращается руна и количество байтов, занятых её
  кодом `UTF-8`;
* Цикл по диапазону Go, применённый к строке, выполняет декодирование `UTF-8` неявно (каждый элемент строки,
  рассматривается как `rune`);
* Чтобы посчитать количество рун в строке, можно использовать простой цикл `range` или
  функцию `utf8.RuneCountInString(s)`;
* Тексты строк в Go интерпретируются как последовательности символов `Unicode` в кодировке `UTF-8`, это необходимо для
  правильного использования циклов по диапазону;
* Если в строке содержатся ошибки кодировки, то при декодировании генерируется специальный замещающий символ Unicode  
  `'\uFFFD'`;
* Преобразование `[]rune` примененное к строке с кодировкой `UTF-8` возвращает последовательность символов `Unicode`,
  закодированных в этой строке;
* Преобразование целочисленного значения в строку рассматривает это число как значение руны и даёт её представление в
  кодировке UTF-8;
* Если руна некорректна, вместо неё подставляется замещающий символ `�`.