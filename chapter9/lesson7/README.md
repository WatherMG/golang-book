# 9.7. Пример: параллельный неблокирующий кеш

В этом разделе мы будем создавать `параллельный неблокирующий кеш` — абстракцию, которая решает проблему, часто
возникающую в реальных параллельных программах, но не решенную окончательно существующими библиотеками. Это проблема
`функций с запоминанием`, т.е. **кеширование результата функции**, так что его нужно **вычислять только один раз**. Наше
решение будет безопасно с точки зрения параллельности и позволит избежать конфликтов, связанных с дизайном на основе
единственной блокировки для всего кеша.

В качестве примера функции с запоминанием воспользуемся функцией `httpGetBody`, показанной ниже. Она делает запрос `HTTP
GET` и читает тело ответа. Вызовы этой функции являются относительно дорогими, поэтому мы хотели бы избежать их
излишнего повторения.

``` go
func httpGetBody(url string) (interface{}, error) {
	resp, err := http.Get(url)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()
	return io.ReadAll(resp.Body)
}
```

В последней строке скрывается небольшая тонкость. `ReadAll` возвращает два результата, `[]byte` и `error`, но поскольку
эти типы присваиваемы объявленным результатам `httpGetBody` — `interface{}` и `error` соответственно, — мы можем просто
вернуть результат вызова без дальнейших церемоний. Мы выбрали этот тип возвращаемого значения для `httpGetBody` так,
чтобы он соответствовал типу функций, для которых разрабатывается наш кеш, предназначенный для запоминания.

Вот первый набросок кеша (см. memo1.go):

``` go
// Memo кеширует результаты вызова Func.
type Memo struct {
	f     Func
	cache map[string]result
}

// Func является типом функции с запоминанием.
type Func func(key string) (interface{}, error)
type result struct {
	value interface{}
	err   error
}

func New(f Func) *Memo {
	return &Memo{f: f, cache: make(map[string]result)}
}

// Примечание: небезопасно с точки зрения параллелизма!
func (memo *Memo) Get(key string) (interface{}, error) {
	res, ok := memo.cache[key]
	if !ok {
		res.value, res.err = memo.f(key)
		memo.cache[key] = res
	}
	return res.value, res.err
}
```

Экземпляр `Memo` содержит функцию `f` (результаты выполнения которой будут запоминаться) с типом `Func` и `кеш`, который
представляет собой карту строк на `result`. Каждый `result` представляет собой просто пару результатов, возвращаемых
вызовом `f`, — **значение и ошибку**. Мы покажем несколько вариаций `Memo` по ходу развития дизайна, но все они будут
использовать эти базовые свойства.Пример использования `Memo` показан ниже. Для каждого элемента в потоке входящих URL
мы вызываем `Get` и протоколируем продолжительность вызова и количество данных, которые он возвращает:

``` go
func Sequential(t *testing.T, m M) {
	for url := range incomingURLs() {
		start := time.Now()
		value, err := m.Get(url)
		if err != nil {
			log.Print(err)
			continue
		}
		fmt.Printf("%s, %s, %d bytes\n", url, time.Since(start), len(value.([]byte)))
	}
}
```

Для систематического исследования эффекта запоминания можно использовать пакет `testing` (это тема главы 11,
“Тестирование”). Из выходных данных теста, приведенных ниже, видно, что поток URL содержит дубликаты и что, хотя первый
вызов `(*Memo).Get` для каждого URL занимает сотни миллисекунд, второй запрос возвращает такое же количество данных в
пределах миллисекунды:

``` shell
=== RUN   TestSequential
https://golang.org, 346.5076ms, 1579 bytes
https://godoc.org, 249.3752ms, 295 bytes
https://play.golang.org, 356.9421ms, 1579 bytes
http://gopl.io, 1.24594s, 4154 bytes
https://golang.org, 0s, 1579 bytes
https://godoc.org, 0s, 295 bytes
https://play.golang.org, 0s, 1579 bytes
http://gopl.io, 0s, 4154 bytes
--- PASS: TestSequential (2.20s)
PASS

```

**Этот тест выполняет все вызовы `Get` последовательно.**

Поскольку HTTP-запросы — отличная возможность применения параллелизма, давайте изменим тест так, чтобы он выполнял все
запросы параллельно. В тесте используется `sync.WaitGroup` — для ожидания при завершении программы, пока последний
запрос не будет полностью выполнен:

``` go
func Concurrent(t *testing.T, m M) {
	var wg sync.WaitGroup
	for url := range incomingURLs() {
		wg.Add(1)
		go func(u string) {
			defer wg.Done()
			start := time.Now()
			value, err := m.Get(u)
			if err != nil {
				log.Print(err)
				return
			}
			fmt.Printf("%s, %s, %d bytes\n", u, time.Since(start), len(value.([]byte)))
		}(url)
	}
	wg.Wait()
}
```

Этот тест выполняется гораздо быстрее, но, к сожалению, непохоже, что он корректно работает все время. Мы можем заметить
неожиданные отсутствия информации в кеше или выборки из кеша, возвращающие неправильные значения, или даже паники.

Но хуже всего, то, что он может корректно работать некоторое время, так что мы можем даже не заметить наличие проблем.
Но если мы запустим код с флагом `-race`, `детектор гонки` (раздел 9.6) может вывести отчет наподобие следующего:

``` shell
go test -race -run=TestConcurrent
https://godoc.org, 375.3139ms, 295 bytes
==================
WARNING: DATA RACE
Write at 0x00c0000b4ea0 by goroutine 14:
  runtime.mapassign_faststr()
      /usr/local/go/src/runtime/map_faststr.go:203 +0x0
  GolangBook/chapter9/lesson7/memo1.(*Memo).Get()
      /mnt/d/Projects/Golang/src/GolangBook/chapter9/lesson7/memo1/memo.go:30 +0x12c
  GolangBook/chapter9/lesson7/memotest.Concurrent.func1()
      /mnt/d/Projects/Golang/src/GolangBook/chapter9/lesson7/memotest/memotest.go:72 +0xea
  GolangBook/chapter9/lesson7/memotest.Concurrent.func2()
      /mnt/d/Projects/Golang/src/GolangBook/chapter9/lesson7/memotest/memotest.go:78 +0x58

Previous write at 0x00c0000b4ea0 by goroutine 10:
  runtime.mapassign_faststr()
      /usr/local/go/src/runtime/map_faststr.go:203 +0x0
  GolangBook/chapter9/lesson7/memo1.(*Memo).Get()
      /mnt/d/Projects/Golang/src/GolangBook/chapter9/lesson7/memo1/memo.go:30 +0x12c
  GolangBook/chapter9/lesson7/memotest.Concurrent.func1()
      /mnt/d/Projects/Golang/src/GolangBook/chapter9/lesson7/memotest/memotest.go:72 +0xea
  GolangBook/chapter9/lesson7/memotest.Concurrent.func2()
      /mnt/d/Projects/Golang/src/GolangBook/chapter9/lesson7/memotest/memotest.go:78 +0x58
==================
https://godoc.org, 376.5965ms, 295 bytes
https://golang.org, 414.448801ms, 1579 bytes
https://golang.org, 417.672401ms, 1579 bytes
https://play.golang.org, 433.840201ms, 1579 bytes
https://play.golang.org, 435.332201ms, 1579 bytes
http://gopl.io, 1.497378202s, 4154 bytes
http://gopl.io, 1.503208002s, 4154 bytes
--- FAIL: TestConcurrent (1.50s)
    testing.go:1446: race detected during execution of test
FAIL
exit status 1

```

Ссылка на `memo.go:30` говорит нам о том, что две горутины обновили карту кеша без какой-либо промежуточной
синхронизации. Метод `Get` не является безопасным с точки зрения параллельности: в нем имеется гонка данных:

``` go
func (memo *Memo) Get(key string) (interface{}, error) {
	res, ok := memo.cache[key]
	if !ok {
		res.value, res.err = memo.f(key)
		memo.cache[key] = res
	}
	return res.value, res.err
}
```

Самый простой способ сделать кеш безопасным с точки зрения параллельности — использовать синхронизацию на основе
`монитора`. Все, что нужно сделать, — это **добавить мьютекс** в `Memo`, **захват мьютекса** в начале `Get` и *
*освобождение** его до выхода из `Get` так, чтобы две операции с `cache` выполнялись в критическом разделе:

``` go
type Memo struct {
	f     Func
	mu    sync.Mutex // Защита cache
	cache map[string]result
}

// Метод Get безопасен с точки зрения параллельности.
func (memo *Memo) Get(key string) (value interface{}, err error) {
	memo.mu.Lock()
	res, ok := memo.cache[key]
	if !ok {
		res.value, res.err = memo.f(key)
		memo.cache[key] = res
	}
	memo.mu.Unlock()
	return res.value, res.err
}
```

Теперь детектор гонки молчит даже при параллельном выполнении тестов. К сожалению, это изменение `Memo` **отменяет**
добытый ранее прирост производительности. Применяя блокировку на время, равное продолжительности каждого
вызова `f`, `Get` сериализует все операции ввода-вывода, которые мы намеревались сделать параллельными. Нам нужен
`неблокирующий кеш`, не сериализующий вызовы функции, для запоминания результатов которой он предназначен.

В следующей реализации `Get` вызывающая горутина выполняет блокировку дважды: один раз — **для поиска**, а второй раз —
**для обновления**, если поиск неудачен. Между ними другие горутины могут свободно использовать кеш.

``` go
// Метод Get безопасен с точки зрения параллельности.
func (memo *Memo) Get(key string) (value interface{}, err error) {
	memo.mu.Lock()
	res, ok := memo.cache[key]
	memo.mu.Unlock()
	if !ok {
		res.value, res.err = memo.f(key)
		// Между этими двумя критическими разделами
		// несколько горутин могут вычислять f(key)
		// и обновлять карту
		memo.mu.Lock()
		memo.cache[key] = res
		memo.mu.Unlock()
	}
	return res.value, res.err
}
```

Производительность снова улучшается, но теперь мы замечаем, что некоторые URL выбираются дважды. Это происходит, когда
две или более горутин вызывают `Get` для одного и того же URL в **одно и то же время**. Обе выполняют поиск в кеше, не
находят искомого значения, а затем вызывают медленную функцию `f`. После этого обе горутины обновляют карту
полученным результатом. В итоге один результат заменяется другим.

В идеале хотелось бы избежать такой лишней работы. Эта возможность иногда называется `подавлением повторений`. В версии
`Memo` ниже каждый элемент карты является **указателем на структуру** `entry`. Каждый элемент `entry` содержит
**записанный результат вызова функции** `f`, как и прежде, но теперь он дополнительно содержит **канал** с
именем `ready`. Сразу после того, как поле `result` структуры `entry` оказывается записанным, этот канал закрывается,
широковещательно оповещая (раздел 8.9) все прочие горутины о том, что теперь можно безопасно читать результат из этого
элемента `entry` (см. memo4.go).

``` go
type entry struct {
	res   result
	ready chan struct{} // Закрывается, когда res готов
}

type Memo struct {
	f     Func
	mu    sync.Mutex // Защита cache
	cache map[string]*entry
}

func New(f Func) *Memo {
	return &Memo{f: f, cache: make(map[string]*entry)}
}

// Метод Get безопасен с точки зрения параллельности.
func (memo *Memo) Get(key string) (value interface{}, err error) {
	memo.mu.Lock()
	e := memo.cache[key]
	if e == nil {
		// Это первый запрос данного ключа.
		// Эта горутина становиться ответственной за
		// вычисление значения и оповещение о готовности.
		e = &entry{ready: make(chan struct{})}
		memo.cache[key] = e
		memo.mu.Unlock()

		e.res.value, e.res.err = memo.f(key)
		close(e.ready) // Широковещательное оповещение о готовности
	} else {
		// Это повторный запрос данного ключа.
		memo.mu.Unlock()

		<-e.ready // Ожидание готовности
	}
	return e.res.value, e.res.err
}
```

Вызов `Get` теперь включает в себя захват мьютекса, охраняющего карту кеша, поиск в отображении указателя на
существующую запись `entry`, выделение памяти и вставку новой записи, если поиск был неудачен, и освобождение мьютекса.
Если же имеется существующая запись, ее значение необязательно готово — в этот момент другая горутина может
осуществлять вызов медленной функции `f`, — так что вызывающая горутина должна ожидать оповещения о готовности,
прежде чем читать `result` из записи `entry`. Она делает это, выполняя чтение из канала `ready`, поскольку эта операция
блокирует горутину до тех пор, пока канал не будет закрыт.

Если нет соответствующего существующего элемента `entry`, то путем вставки нового `"не готового"` элемента в карту
текущая горутина берет на себя ответственность за вызов медленной функции, обновление записи и оповещение о
готовности новой записи всех других горутин, которые могут (к тому времени) ее ожидать.

Обратите внимание, что переменные `е.res.value` и `е.res.err` в `entry` совместно используются несколькими
горутинами. Горутина, которая создает `entry`, устанавливает их значения, а другие горутины читают их
значения **только после широковещательного оповещения о состоянии готовности**. Несмотря на обращение со стороны
нескольких горутин, **мьютекс не является необходимым**. Закрытие канала `ready` `предшествует` получению оповещения
любыми другими горутинами, поэтому запись в эти переменные в первой горутине `предшествует` их чтению последующими
горутинами. В результате никакой гонки данных не существует.

Наш параллельный, неблокирующий кеш без дублирования готов.

Показанная выше реализация `Memo` использует мьютекс для защиты переменной карты, которая используется совместно
всеми горутинами, которые вызывают метод `Get`. Интересно сравнить этот дизайн с альтернативным, в котором
переменная карты ограничена управляющей горутиной, которой абоненты `Get` должны отправлять сообщение.

Объявления `Func`, `result` и `entry` остаются такими же, как и ранее:

``` go
// Func представляет собой тип функции,
// для которой реализуется запоминание.
type Func func(key string) (interface{}, error)

// result представляет собой результат вызова Func. 
type result struct { 
	value interface{} 
	err error
}
type entry struct { 
	res result
	ready chan struct{} // Закрыт, когда res готов
}
```

Однако тип `Memo` теперь состоит из канала, `requests`, через который функция, вызывающая `Get`, взаимодействует с
управляющей
горутиной. Типом элемента канала является `request`. С помощью этой структуры вызывающая `Get` функция отправляет
управляющей горутине как ключ, т.е. аргумент функции с запоминанием, так и еще один канал, `response`, по которому
результат должен отправляться обратно, когда он становится доступным. Этот канал будет переносить только одно значение.

``` go
// requests представляет собой сообщение,
// требующее применения Func к key.
type request struct {
	key      string
	response chan<- result
	// Клиенту нужен только result
}

type Memo struct {
	requests chan request
}

// Func является типом функции с запоминанием.
type Func func(key string) (interface{}, error)

type result struct {
	value interface{}
	err   error
}

// New возвращает f с запоминанием.
// Впоследствии клиенты должны вызывать Close.
func New(f Func) *Memo {
	memo := &Memo{requests: make(chan request)}
	go memo.server(f)
	return memo
}

// Метод Get безопасен с точки зрения параллельности.
func (memo *Memo) Get(key string) (value interface{}, err error) {
	response := make(chan result)
	memo.requests <- request{key, response}
	res := <-response
	return res.value, res.err
}

func (memo *Memo) Close() { close(memo.requests) }
```

Приведенный выше метод `Get` создает канал `response`, помещает его в запрос и отправляет запрос управляющей
горутине, после чего сразу же переходит к получению ответа из этого канала.

Переменная `cache` ограничена управляющей горутиной `(*Memo).server`, показанной ниже. Она считывает запросы в цикле
до тех пор, пока канал не будет закрыт с помощью метода `Close`. Для каждого запроса она обращается к кешу, создавая и
вставляя новую запись `entry`, если таковая не была найдена.

``` go
func (memo *Memo) server(f Func) {
	cache := make(map[string]*entry)
	for req := range memo.requests {
		e := cache[req.key]
		if e == nil {
			// Это первый запрос данного ключа key
			e = &entry{ready: make(chan struct{})}
			cache[req.key] = e
			go e.call(f, req.key) // Вызов f(key)
		}
		go e.deliver(req.response)
	}
}

func (e *entry) call(f Func, key string) {
	// Вычисление функции.
	e.res.value, e.res.err = f(key)
	// Оповещение о готовности
	close(e.ready)
}

func (e *entry) deliver(response chan<- result) {
	// Ожидание готовности
	<-e.ready
	// Отправка результата клиенту
	response <- e.res
}
```

Способом, аналогичным версии на основе мьютекса, первый запрос некоторого ключа становится ответственным за вызов
функции `f` для этого ключа, сохранение результата в `entry` и оповещение о готовности с помощью закрытия `ready`. Это
делается с помощью вызова `(*entry).call`.

Последующий запрос того же ключа находит существующую запись `entry` в карте, ждет, когда результат будет готов, и
отправляет его по каналу клиентской горутине, которая вызвала `Get`. Это делается с помощью вызова `(*entry).deliver`.
Методы `call` и `deliver` должны вызываться в их собственных горутинах, чтобы гарантировать, что управляющая
горутина не остановит обработку новых запросов.

Этот пример показывает, что можно построить много параллельных структур, используя любой из подходов — с `совместно
используемыми переменными и блокировками` или со `взаимодействующими последовательными процессами`, — без чрезмерной
сложности.

Не всегда очевидно, какой именно подход предпочтителен в данной ситуации, но стоит знать оба. Иногда переход от одного
подхода к другому позволяет существенно упростить код.

## Выводы:

* Создание `параллельного неблокирующего кеша` может решить **проблему функций с запоминанием в параллельных
  программах**, позволяя кешировать результаты функций и избежать излишнего повторения дорогостоящих операций;
* Пример функции с запоминанием - `httpGetBody`, делающая HTTP GET запрос и читающая тело ответа. Хранение результатов
  этой функции может существенно ускорить программу;
* `Memo`, (memo2) использующий функцию `f` и кеш на основе карты строк, позволяет кешировать результаты выполнения
  функций и предоставлять их быстро при повторных запросах;
* Использование параллелизма в программе может значительно ускорить выполнение операций ввода-вывода, особенно при
  наличии дубликатов `URL-адресов`;
* Простой способ сделать кеш безопасным с точки зрения параллельности - использовать синхронизацию на `основе монитора (
  мьютекс)`, однако это может сериализовать операции ввода-вывода и уменьшить преимущества параллелизма;
* Для решения этой проблемы и обеспечения корректной работы кеша в условиях параллелизма, можно использовать другие
  подходы, например, `разделение блокировок` или `алгоритмы без блокировок`;
* В реализации `Get` (memo3) горутина выполняет блокировку дважды: `для поиска` и `для обновления`; это позволяет
  улучшить производительность и предотвращает блокировки при использовании кеша.
* Некоторые URL могут выбираться дважды при одновременных вызовах `Get`: это приводит к лишней работе, поэтому следует
  использовать подавление повторений для более эффективной работы с кешем.
* В версии 4 `Memo` (memo4) каждый элемент карты является указателем на структуру `entry`, которая содержит результат
  вызова функции `f` и канал с именем `ready`; закрытие канала оповещает другие горутины о готовности результата.
* `Get` включает захват мьютекса, поиск существующей записи `entry`, выделение памяти, вставку новой записи и
  освобождение мьютекса; это обеспечивает параллельность и неблокирование кеша.
* Если существующая запись `entry` не готова, горутина должна ожидать оповещения о готовности перед чтением значения;
  это достигается с помощью чтения из канала `ready`.
* Получение оповещения о готовности и чтение результатов в других горутинах происходит после записи данных в первой
  горутине, поэтому не требуется мьютекс и нет гонок данных.
* Можно использовать альтернативный дизайн кеша с `ограниченной управляющей горутиной и каналами` для отправки запросов
  и получения результатов, что также обеспечит безопасность доступа к данным и параллельность работы.
* Управляющая горутина обрабатывает запросы, вызывает функцию `f`, сохраняет результат и оповещает о готовности с
  помощью методов `call` и `deliver`; эти методы вызываются в отдельных горутинах для предотвращения блокировки
  обработки новых запросов.
* Разные подходы к параллельности и синхронизации данных (**с совместно используемыми переменными и блокировками** или *
  *со взаимодействующими последовательными процессами**) могут быть использованы без чрезмерной сложности, и иногда
  переход от одного подхода к другому упрощает код.
* Знание обоих подходов помогает выбрать наиболее подходящий для конкретной ситуации и создать эффективные параллельные
  алгоритмы и структуры данных на языке Golang.